{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJmxi0e-9pRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87f479f-e337-4dd7-aca5-adfdde2a6bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1RrognTx42u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0d9314-fb9c-4d70-b9ab-760ed5ec7763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['large.cell.carcinoma', 'adenocarcinoma', 'squamous.cell.carcinoma', 'normal']\n"
          ]
        }
      ],
      "source": [
        "# path of dataset file\n",
        "import os\n",
        "dataset = \"/content/drive/MyDrive/Lung Dataset /Chest CT Scan Images/\"\n",
        "print(os.listdir(dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkEejDh35nmc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LeNet architecture\n",
        "class LeNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetFeatureExtractor, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Adjusted this line\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, 16 * 5 * 5)  # Adjusted this line\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "lenet_extractor = LeNetFeatureExtractor()\n",
        "lenet_extractor.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the transform to match LeNet's input requirements\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
        "    transforms.Resize((32, 32)),                 # Resize to 32x32\n",
        "    transforms.ToTensor()                        # Convert to tensor\n",
        "])\n"
      ],
      "metadata": {
        "id": "XbhI1Q2EKpeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `dataset` is the path to your dataset\n",
        "classes = os.listdir(dataset)\n",
        "features_list = []\n",
        "labels_list = []\n",
        "\n",
        "for label, class_dir in enumerate(classes):\n",
        "    class_path = os.path.join(dataset, class_dir)\n",
        "    for image_name in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, image_name)\n",
        "        image = Image.open(image_path).convert('L')  # Open image and convert to grayscale\n",
        "        image = transform(image)                    # Apply transforms\n",
        "        image = image.unsqueeze(0)                  # Add batch dimension\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = lenet_extractor(image)       # Extract features\n",
        "            features = features.numpy().flatten()   # Flatten the output to a 1D array\n",
        "\n",
        "        features_list.append(features)\n",
        "        labels_list.append(label)\n",
        "\n",
        "features = np.vstack(features_list)\n",
        "labels = np.hstack(labels_list)\n",
        "\n",
        "print(f'Features shape: {features.shape}')\n",
        "print(f'Labels shape: {labels.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLp7zjUHM3Xr",
        "outputId": "21b77f26-33cc-4550-b605-1410fd75d143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (1000, 84)\n",
            "Labels shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mt3knxO6O39"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels_list, test_size=0.3, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(fpr, tpr, roc_auc, title):\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Train and evaluate SVM\n",
        "svm = SVC(kernel='poly', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "y_score_svm = svm.decision_function(X_test)\n",
        "\n",
        "# Compute metrics for SVM\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)\n",
        "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm:.4f}')\n",
        "print(f'SVM Precision: {precision_svm:.4f}')\n",
        "print(f'SVM Recall: {recall_svm:.4f}')\n",
        "print(f'SVM F1 Score: {f1_svm:.4f}')\n",
        "print(f'SVM AUC: {roc_auc_svm:.4f}')\n",
        "\n",
        "# Plot ROC curve for SVM\n",
        "plot_roc_curve(fpr_svm, tpr_svm, roc_auc_svm, 'SVM ROC Curve')\n",
        "\n",
        "# Confusion matrix for SVM\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "disp_svm = ConfusionMatrixDisplay(confusion_matrix=cm_svm)\n",
        "disp_svm.plot()\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "5DfaOOAktAEv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "269245af-a5af-4e2b-9c1d-ca78227e4437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b5fed3575852>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Compute metrics for SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0maccuracy_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprecision_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mrecall_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mf1_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m     \"\"\"\n\u001b[0;32m-> 2131\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   2132\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1722\u001b[0m     \"\"\"\n\u001b[1;32m   1723\u001b[0m     \u001b[0mzero_division_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1519\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}